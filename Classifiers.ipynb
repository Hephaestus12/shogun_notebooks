{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shogun Vs Sklearn : Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from modshogun import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generation1 = datasets.make_classification(n_samples=700, n_features=15,n_classes=2,n_informative=5)\n",
    "generation2 = datasets.make_classification(n_samples=5000, n_features=20,n_classes=5,n_informative=5)\n",
    "generation3 = datasets.make_classification(n_samples=20000, n_features=50,n_classes=10,n_informative=5)\n",
    "\n",
    "feats1 = generation1[0]\n",
    "labels1 = generation1[1]\n",
    "\n",
    "feats2 = generation2[0]\n",
    "labels2 = generation2[1]\n",
    "\n",
    "feats3 = generation3[0]\n",
    "labels3 = generation3[1]\n",
    "\n",
    "feats1_train = feats1[:600]\n",
    "feats1_test = feats1[600:]\n",
    "labels1_train = labels1[:600]\n",
    "labels1_test = labels1[600:]\n",
    "\n",
    "feats2_train = feats2[:4500]\n",
    "feats2_test = feats2[4500:]\n",
    "labels2_train = labels2[:4500]\n",
    "labels2_test = labels2[4500:]\n",
    "\n",
    "feats3_train = feats3[:19000]\n",
    "feats3_test = feats3[19000:]\n",
    "labels3_train = labels3[:19000]\n",
    "labels3_test = labels3[19000:]\n",
    "\n",
    "feats1_train.reshape(len(feats1_train[0,:]),len(feats1_train[:,0]))\n",
    "shogun_feats1_train = RealFeatures(feats1_train.reshape(len(feats1_train[0,:]),len(feats1_train[:,0])))\n",
    "shogun_feats1_test = RealFeatures(feats1_test.reshape(len(feats1_test[0,:]),len(feats1_test[:,0])))\n",
    "shogun_labels1_train = MulticlassLabels(labels1_train*1.0)\n",
    "shogun_labels1_test = MulticlassLabels(labels1_test*1.0)\n",
    "\n",
    "shogun_feats2_train = RealFeatures(feats2_train.reshape(len(feats2_train[0,:]),len(feats2_train[:,0])))\n",
    "shogun_feats2_test = RealFeatures(feats2_test.reshape(len(feats2_test[0,:]),len(feats2_test[:,0])))\n",
    "shogun_labels2_train = MulticlassLabels(labels2_train*1.0)\n",
    "shogun_labels2_test = MulticlassLabels(labels2_test*1.0)\n",
    "\n",
    "shogun_feats3_train = RealFeatures(feats3_train.reshape(len(feats3_train[0,:]),len(feats3_train[:,0])))\n",
    "shogun_feats3_test = RealFeatures(feats3_test.reshape(len(feats3_test[0,:]),len(feats3_test[:,0])))\n",
    "shogun_labels3_train = MulticlassLabels(labels3_train*1.0)\n",
    "shogun_labels3_test = MulticlassLabels(labels3_test*1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset 1 , size 600 , Dimensions 15 , classes 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n",
      "0.00019907951355\n",
      "0.84\n",
      "0.000859022140503\n"
     ]
    }
   ],
   "source": [
    "number_of_neighbors = 10\n",
    "\n",
    "start = time.time()\n",
    "distances1 = EuclideanDistance(shogun_feats1_train, shogun_feats1_train)\n",
    "shogun_knn1 = KNN(number_of_neighbors,distances1,shogun_labels1_train)\n",
    "shogun_knn1.train()\n",
    "end = time.time()\n",
    "\n",
    "print np.sum((labels1_test == shogun_knn1.apply(shogun_feats1_test).get_labels()))/100.0\n",
    "print end-start\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start = time.time()\n",
    "sklearn_knn1 =KNeighborsClassifier(n_neighbors=number_of_neighbors)\n",
    "sklearn_knn1.fit(feats1_train,labels1_train)\n",
    "end = time.time()\n",
    "print np.sum(sklearn_knn1.predict(feats1_test) == labels1_test)/100.0\n",
    "print end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.198\n",
      "0.000261068344116\n",
      "0.672\n",
      "0.00358915328979\n"
     ]
    }
   ],
   "source": [
    "number_of_neighbors = 10\n",
    "\n",
    "start = time.time()\n",
    "distances2 = EuclideanDistance(shogun_feats2_train, shogun_feats2_train)\n",
    "shogun_knn2 = KNN(number_of_neighbors,distances2,shogun_labels2_train)\n",
    "shogun_knn2.train()\n",
    "end = time.time()\n",
    "print sum(labels2_test == shogun_knn2.apply(shogun_feats2_test).get_labels())/500.0\n",
    "print end-start\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start = time.time()\n",
    "sklearn_knn2 =KNeighborsClassifier(n_neighbors=number_of_neighbors)\n",
    "sklearn_knn2.fit(feats2_train,labels2_train)\n",
    "end = time.time()\n",
    "print sum(sklearn_knn2.predict(feats2_test) == labels2_test)/500.0\n",
    "print end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327\n",
      "0.764\n"
     ]
    }
   ],
   "source": [
    "number_of_neighbors = 10\n",
    "\n",
    "distances3 = EuclideanDistance(shogun_feats3_train, shogun_feats3_train)\n",
    "shogun_knn3 = KNN(number_of_neighbors,distances3,shogun_labels3_train)\n",
    "shogun_knn3.train()\n",
    "print sum(labels3_test == shogun_knn3.apply(shogun_feats3_test).get_labels())/1000.0\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "sklearn_knn3 =KNeighborsClassifier(n_neighbors=number_of_neighbors)\n",
    "sklearn_knn3.fit(feats3_train,labels3_train)\n",
    "print sum(sklearn_knn3.predict(feats3_test) == labels3_test)/1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comments on KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- very low accuracy !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-many options at sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "shogun_naive1 = GaussianNaiveBayes()\n",
    "shogun_naive1.set_features(shogun_feats1_train)\n",
    "shogun_naive1.set_labels(shogun_labels1_train)\n",
    "shogun_naive1.train()\n",
    "print np.sum((labels1_test == shogun_naive1.apply(shogun_feats1_test).get_labels()))/100.0\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "sklearn_naive1 = GaussianNB()\n",
    "sklearn_naive1.fit(feats1_train, labels1_train)\n",
    "\n",
    "print np.sum(labels1_test == sklearn_naive1.predict(feats1_test))/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.196\n",
      "0.552\n"
     ]
    }
   ],
   "source": [
    "shogun_naive2 = GaussianNaiveBayes()\n",
    "shogun_naive2.set_features(shogun_feats2_train)\n",
    "shogun_naive2.set_labels(shogun_labels2_train)\n",
    "shogun_naive2.train()\n",
    "print np.sum((labels2_test == shogun_naive2.apply(shogun_feats2_test).get_labels()))/500.0\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "sklearn_naive2 = GaussianNB()\n",
    "sklearn_naive2.fit(feats2_train, labels2_train)\n",
    "\n",
    "print np.sum(labels2_test == sklearn_naive2.predict(feats2_test))/500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.348\n",
      "0.649\n"
     ]
    }
   ],
   "source": [
    "shogun_naive3 = GaussianNaiveBayes()\n",
    "shogun_naive3.set_features(shogun_feats3_train)\n",
    "shogun_naive3.set_labels(shogun_labels3_train)\n",
    "shogun_naive3.train()\n",
    "print np.sum((labels3_test == shogun_naive3.apply(shogun_feats3_test).get_labels()))/1000.0\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "sklearn_naive3 = GaussianNB()\n",
    "sklearn_naive3.fit(feats3_train, labels3_train)\n",
    "\n",
    "print np.sum(labels3_test == sklearn_naive3.predict(feats3_test))/1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comments on Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lower accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51\n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "shogun_qda1 = QDA(shogun_feats1_train, shogun_labels1_train)\n",
    "shogun_qda1.train()\n",
    "print np.sum((labels1_test == shogun_qda1.apply(shogun_feats1_test).get_labels()))/100.0\n",
    "\n",
    "from sklearn import qda\n",
    "sklearn_qda1 = qda.QDA()\n",
    "sklearn_qda1.fit(feats1_train,labels1_train)\n",
    "print np.sum(labels1_test == sklearn_qda1.predict(feats1_test))/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.188\n",
      "0.57\n"
     ]
    }
   ],
   "source": [
    "shogun_qda2 = QDA(shogun_feats2_train, shogun_labels2_train)\n",
    "shogun_qda2.train()\n",
    "print np.sum((labels2_test == shogun_qda2.apply(shogun_feats2_test).get_labels()))/500.0\n",
    "\n",
    "sklearn_qda2 = qda.QDA()\n",
    "sklearn_qda2.fit(feats2_train,labels2_train)\n",
    "print np.sum(labels2_test == sklearn_qda2.predict(feats2_test))/500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.332\n",
      "0.723\n"
     ]
    }
   ],
   "source": [
    "shogun_qda3 = QDA(shogun_feats3_train, shogun_labels3_train)\n",
    "shogun_qda3.train()\n",
    "print np.sum((labels3_test == shogun_qda3.apply(shogun_feats3_test).get_labels()))/1000.0\n",
    "\n",
    "sklearn_qda3 = qda.QDA()\n",
    "sklearn_qda3.fit(feats3_train,labels3_train)\n",
    "print np.sum(labels3_test == sklearn_qda3.predict(feats3_test))/1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47\n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "shogun_log1 = MulticlassLogisticRegression(1,shogun_feats1_train,shogun_labels1_train)\n",
    "shogun_log1.train()\n",
    "\n",
    "print np.sum((labels1_test == shogun_log1.apply(shogun_feats1_test).get_labels()))/100.0\n",
    "\n",
    "from sklearn import linear_model\n",
    "sklearn_log1 = linear_model.LogisticRegression()\n",
    "sklearn_log1.fit(feats1_train,labels1_train)\n",
    "print np.sum(labels1_test == sklearn_qda1.predict(feats1_test))/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.208\n",
      "0.57\n"
     ]
    }
   ],
   "source": [
    "shogun_log2 = MulticlassLogisticRegression(1,shogun_feats2_train,shogun_labels2_train)\n",
    "shogun_log2.train()\n",
    "\n",
    "print np.sum((labels2_test == shogun_log2.apply(shogun_feats2_test).get_labels()))/500.0\n",
    "\n",
    "from sklearn import linear_model\n",
    "sklearn_log2 = linear_model.LogisticRegression()\n",
    "sklearn_log2.fit(feats2_train,labels2_train)\n",
    "print np.sum(labels2_test == sklearn_qda2.predict(feats2_test))/500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.344\n",
      "0.723\n"
     ]
    }
   ],
   "source": [
    "shogun_log3 = MulticlassLogisticRegression(1,shogun_feats3_train,shogun_labels3_train)\n",
    "shogun_log3.train()\n",
    "\n",
    "print np.sum((labels3_test == shogun_log3.apply(shogun_feats3_test).get_labels()))/1000.0\n",
    "\n",
    "from sklearn import linear_model\n",
    "sklearn_log3 = linear_model.LogisticRegression()\n",
    "sklearn_log3.fit(feats3_train,labels3_train)\n",
    "print np.sum(labels3_test == sklearn_qda3.predict(feats3_test))/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
